{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6768e895",
   "metadata": {},
   "source": [
    "# ReID Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a242b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Outline:\n",
    "\n",
    "a basline for Person ReID\n",
    "market1501 --> ask @ TA\n",
    "training data: '00001': [img1, img2, img3,...]\n",
    "testing data: [img ...]? \n",
    "\n",
    "Given a query photo, recognize person ID ?  < == image search / retrieval\n",
    "Gallery : image database <== training data + testing data (only a few)\n",
    "\n",
    "q, g_i in G : learn a (similarity / distance) function: s(q, g_i) ? \n",
    "\n",
    "Suppose q and g_i are feature vectors, s(q, g_i)  = q dot_product g_i \n",
    "\n",
    "ConvNet e.g. ResNet-50 / MobileNet  == > Train a ConvNet\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e2d50bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "img_width = 64\n",
    "img_height =64\n",
    "learning_rate = 0.01\n",
    "\n",
    "optimizer = SGD(learning_rate = learning_rate)\n",
    "batch_size = 256\n",
    "nbr_epochs = 20\n",
    "\n",
    "# define own leraning rate updates\n",
    "def lr_decay_basic(epoch, initial_lrate):\n",
    "    decay_epochs = [40, 70]\n",
    "    if epoch in decay_epochs:\n",
    "        decay_rate = 0.1\n",
    "        new_lrate = initial_lrate * decay_rate\n",
    "        return new_lrate\n",
    "    else:\n",
    "        return initial_lrate\n",
    "\n",
    "data_folder = '/Users/DanDan/Desktop/七月在线/机器学习原理/第六阶段CV推荐NLP实战/CV/Market-1501-v15.09.15/bounding_box_train'\n",
    "# 12936 images in the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1efdd5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of person ids 751\n"
     ]
    }
   ],
   "source": [
    "# image roots and path, names\n",
    "import os\n",
    "data_root = os.path.join(os.getcwd(), data_folder)\n",
    "image_names = sorted([x for x in os.listdir(data_root) if x.endswith('.jpg')])\n",
    "# image_name: '0002_c2s1_ooo451_003'\n",
    "\n",
    "img_name, img_path = zip(*[(img_file_png[:-4], os.path.join(data_root, img_file_png)\n",
    "                           ) for img_file_png in image_names])\n",
    "\n",
    "person_id_original_list = [x[:4] for x in img_name]\n",
    "\n",
    "nbr_person_ids = len(set(person_id_original_list))   # remove duplicate\n",
    "print('number of person ids', nbr_person_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "109184d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# labelencoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "id_encoder = LabelEncoder()\n",
    "id_encoder.fit(person_id_original_list)\n",
    "person_id_encoded = id_encoder.transform(person_id_original_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6267e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# train images: 10348, # val images: 2588, # image labels: 751\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_img_path, val_img_path, train_person_ids, val_person_ids = train_test_split(\n",
    "                                img_path,person_id_encoded, test_size=0.2, random_state= 42)\n",
    "print('# train images: {}, # val images: {}, # image labels: {}'.format(\n",
    "                len(train_img_path), len(val_img_path), len(set(train_person_ids))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0179eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    }
   ],
   "source": [
    "# input_shape: (batch, height, width, channels)\n",
    "# load pretrained MobileNet - backbone\n",
    "# mobilnetv2 is for smaller datasets\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
    "\n",
    "cnn_model = MobileNetV2(include_top = False, weights = 'imagenet', alpha=0.5, \n",
    "                       input_shape = (img_height, img_width, 3), pooling = 'max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6aee8c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_pool = cnn_model.layers[-1].output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64be990b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Activation\n",
    "# from tensorflow.python.keras.layers import Lambda\n",
    "# from tensorflow.keras.utils import backend as K\n",
    "from keras import backend as K\n",
    "dense_normalized = tensorflow.keras.layers.Lambda(\n",
    "    lambda x: K.l2_normalize(x, axis=1), name='triplet_loss')(global_pool)\n",
    "\n",
    "dense = Dense(nbr_person_ids)(global_pool)\n",
    "softmax_output=Activation('softmax')(dense)\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "triplet_model = Model(cnn_model.input, [dense_normalized, softmax_output])\n",
    "# triplet_model.summary()\n",
    "\n",
    "\n",
    "import tensorflow_addons as tfa\n",
    "triplet_semi_hard_loss = tfa.losses.TripletSemiHardLoss(margin = 0.3)\n",
    "\n",
    "\n",
    "# Label Smoothing -- > overfitting (one-hot encoding )\n",
    "#  [0, 1, 0, 0] --  [0.33, 0.9, 0.33, 0.33]\n",
    "def cross_entropy_label_smoothing(y_true, y_pred):\n",
    "    from tensorflow.keras.losses import categorical_crossentropy\n",
    "    label_smoothing = 0.1\n",
    "    return categorical_crossentropy(y_true, y_pred, label_smoothing = label_smoothing)\n",
    "\n",
    "\n",
    "USE_Label_Smoothing = True\n",
    "if USE_Label_Smoothing:\n",
    "#     from utils import cross_entropy_label_smoothing\n",
    "    triplet_model.compile(loss = [triplet_semi_hard_loss, cross_entropy_label_smoothing],\n",
    "                          optimizer = optimizer,\n",
    "                          metrics = ['accuracy'])\n",
    "else:\n",
    "    triplet_model.compile(loss = [triplet_semi_hard_loss, 'categorical_crossentropy'],\n",
    "                          optimizer = optimizer,\n",
    "                          metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3a1ab20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "# data augmentation: https:github.com/aleju/imgaug\n",
    "# pip install imgaug\n",
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa\n",
    "\n",
    "# Triplet loss  / deep ranking: solution to image retrieval\n",
    "# e.g. amazon shopping in amazon\n",
    "# triplet: (anchor, positive, negative)\n",
    "# loss / target : in feature space, dis(pos, anchor) + margin < dis(neg, anchor)\n",
    "# sampling the triplet data( anchor, pos, neg) is really important! \n",
    "# In the field of person ReID, how to sample data?\n",
    "# anchor shares the same ID with pos, different from neg\n",
    "# Hard Triplet loss (Sampling Hard Data --> hard negative)\n",
    "\n",
    "# from tensorflow.keras.utils import backend as K\n",
    "def triplet_loss(y_true, y_pred, alpha = 0.3):\n",
    "    y_pred = K.l2_normalize(y_pred, axis=1)\n",
    "    \n",
    "    batch_num = y_pred.shape.as_list()[-1] / 3\n",
    "    \n",
    "    anchor = y_pred[:, 0 : batch_num]\n",
    "    positive = y_pred[:, batch_num : batch_num * 2]\n",
    "    negative = y_pred[:, batch_num * 2 : batch_num * 3]\n",
    "    \n",
    "    # distance between the anchor and the positve\n",
    "    pos_dist = K.sum(K.square(anchor - positive), axis=1)\n",
    "    # distance bwteeen the anchor and the negative\n",
    "    neg_dist = K.sum(K.square(anchor - negative), axis=1)\n",
    "    \n",
    "    loss = K.maximum(pos_dist - neg_dist + alpha, 0)  # hinge loss\n",
    "\n",
    "\n",
    "seq = iaa.Sequential()\n",
    "\n",
    "def load_img_batch(img_path_list, img_label_list, nbr_classes, img_width, img_height):\n",
    "    batch_size = len(img_path_list)\n",
    "    \n",
    "    X_batch = np.zeros((batch_size, img_height, img_width, 3))\n",
    "    Y_batch = np.zeros((batch_size, nbr_classes)) # label: one-hot encoding\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        img_path = img_path_list[i]\n",
    "        \n",
    "        \n",
    "        img_bgr = cv2.imread(img_path) # img.shape(128, 64, 3)\n",
    "        if img_bgr.shape != (img_height, img_width, 3):\n",
    "            img_bgr = cv2.resize(img_bgr, (img_width, img_height))\n",
    "            \n",
    "        img = img_bgr[:, :, ::-1]\n",
    "\n",
    "        X_batch[i] = img\n",
    "        \n",
    "        if img_label_list is not None:\n",
    "            label = img_label_list[i]\n",
    "            Y_batch[i, label] = 1\n",
    "            \n",
    "    if img_label_list is not None:\n",
    "        return X_batch, Y_batch\n",
    "    else:\n",
    "        return X_batch\n",
    "    \n",
    "def generator_batch_triplet(img_path_list, img_label_list, nbr_classes, \n",
    "                            img_width, img_height, P=16, K=4, \n",
    "                            shuffle=False, save_to_dir = None, augment=False): \n",
    "    \n",
    "    # img_path_list : ['/home/data/1.jpg', ....]\n",
    "    # img_label_list: [7, 23, 4, ...]\n",
    "    # output: yield (X_batch, y_batch)  or X_batch \n",
    "    \n",
    "    N = len(img_path_list)\n",
    "    if shuffle:\n",
    "        from sklearn.utils import shuffle as shuffle_tuple\n",
    "        img_path_list, img_label_list = shuffle_tuple(img_path_list, img_label_list)\n",
    "        \n",
    "        \n",
    "    dic = {}\n",
    "    for img_label, img_path in zip(img_label_list, img_path_list):\n",
    "        dic.setdefault(img_label, []).append(img_path)\n",
    "        \n",
    "    person_ids_list = [k for k in dic.keys() if len(dic[k]) >= K]\n",
    "    \n",
    "    while True:\n",
    "        import random\n",
    "        person_ids_sampled = random.sample(person_ids_list, k= 4)\n",
    "        img_path_sampled = [random.sample((dic[person_id]),k =4) for person_id in person_ids_sampled]\n",
    "        \n",
    "        img_path_sampled_list = [ ]\n",
    "        [img_path_sampled_list.extend(w) for w in img_path_sampled]\n",
    "        \n",
    "        person_ids_sampled_list = [ ]\n",
    "        tmp_sampled_list = [[w] * K for w in person_ids_sampled]\n",
    "        [person_ids_sampled_list.extend(w) for w in tmp_sampled_list]\n",
    "        \n",
    "        y_batch = np.array(person_ids_sampled_list)\n",
    "        \n",
    "        X_batch, Y_batch = load_img_batch(img_path_sampled_list,\n",
    "                                         person_ids_sampled_list,\n",
    "                                         nbr_classes, img_width, img_height)\n",
    "        \n",
    "        if augment:\n",
    "            X_batch = X_batch.astype(np.uint8)\n",
    "            X_batch_aug = seq.augment_images(X_batch)\n",
    "            X_batch = X_batch_aug\n",
    "            \n",
    "        X_batch = X_batch / 255.\n",
    "        X_batch = (X_batch - np.array([0.485, 0.486, 0.406])) / np.array([0.229, 0.224, 0.225])\n",
    "        yield(X_batch, [y_batch, Y_batch])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5401276f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 1/20\n",
      "40/40 [==============================] - ETA: 0s - loss: 8.4180 - triplet_loss_loss: 0.2886 - activation_loss: 8.1294 - triplet_loss_accuracy: 0.0016 - activation_accuracy: 0.0016WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "40/40 [==============================] - 10s 236ms/step - loss: 8.4180 - triplet_loss_loss: 0.2886 - activation_loss: 8.1294 - triplet_loss_accuracy: 0.0016 - activation_accuracy: 0.0016 - val_loss: 7.8572 - val_triplet_loss_loss: 0.2648 - val_activation_loss: 7.5924 - val_triplet_loss_accuracy: 0.0000e+00 - val_activation_accuracy: 0.0000e+00 - lr: 0.0100\n",
      "\n",
      "Epoch 00002: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 2/20\n",
      "40/40 [==============================] - ETA: 0s - loss: 7.8293 - triplet_loss_loss: 0.2847 - activation_loss: 7.5446 - triplet_loss_accuracy: 0.0016 - activation_accuracy: 0.0016WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "40/40 [==============================] - 8s 200ms/step - loss: 7.8293 - triplet_loss_loss: 0.2847 - activation_loss: 7.5446 - triplet_loss_accuracy: 0.0016 - activation_accuracy: 0.0016 - val_loss: 8.6057 - val_triplet_loss_loss: 0.2521 - val_activation_loss: 8.3536 - val_triplet_loss_accuracy: 0.0000e+00 - val_activation_accuracy: 0.0000e+00 - lr: 0.0100\n",
      "\n",
      "Epoch 00003: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 3/20\n",
      "40/40 [==============================] - ETA: 0s - loss: 7.2482 - triplet_loss_loss: 0.2811 - activation_loss: 6.9670 - triplet_loss_accuracy: 0.0000e+00 - activation_accuracy: 0.0047WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "40/40 [==============================] - 9s 213ms/step - loss: 7.2482 - triplet_loss_loss: 0.2811 - activation_loss: 6.9670 - triplet_loss_accuracy: 0.0000e+00 - activation_accuracy: 0.0047 - val_loss: 8.5407 - val_triplet_loss_loss: 0.2432 - val_activation_loss: 8.2975 - val_triplet_loss_accuracy: 0.0000e+00 - val_activation_accuracy: 0.0125 - lr: 0.0100\n",
      "\n",
      "Epoch 00004: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 4/20\n",
      "40/40 [==============================] - ETA: 0s - loss: 7.1966 - triplet_loss_loss: 0.2807 - activation_loss: 6.9160 - triplet_loss_accuracy: 0.0016 - activation_accuracy: 0.0000e+00WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "40/40 [==============================] - 9s 217ms/step - loss: 7.1966 - triplet_loss_loss: 0.2807 - activation_loss: 6.9160 - triplet_loss_accuracy: 0.0016 - activation_accuracy: 0.0000e+00 - val_loss: 8.8336 - val_triplet_loss_loss: 0.2452 - val_activation_loss: 8.5885 - val_triplet_loss_accuracy: 0.0000e+00 - val_activation_accuracy: 0.0000e+00 - lr: 0.0100\n",
      "\n",
      "Epoch 00005: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 5/20\n",
      "40/40 [==============================] - ETA: 0s - loss: 7.0665 - triplet_loss_loss: 0.2713 - activation_loss: 6.7951 - triplet_loss_accuracy: 0.0000e+00 - activation_accuracy: 0.0000e+00WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "40/40 [==============================] - 9s 229ms/step - loss: 7.0665 - triplet_loss_loss: 0.2713 - activation_loss: 6.7951 - triplet_loss_accuracy: 0.0000e+00 - activation_accuracy: 0.0000e+00 - val_loss: 8.0914 - val_triplet_loss_loss: 0.2249 - val_activation_loss: 7.8665 - val_triplet_loss_accuracy: 0.0000e+00 - val_activation_accuracy: 0.0000e+00 - lr: 0.0100\n",
      "\n",
      "Epoch 00006: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 6/20\n",
      "40/40 [==============================] - ETA: 0s - loss: 6.9803 - triplet_loss_loss: 0.2693 - activation_loss: 6.7111 - triplet_loss_accuracy: 0.0016 - activation_accuracy: 0.0047WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "40/40 [==============================] - 8s 212ms/step - loss: 6.9803 - triplet_loss_loss: 0.2693 - activation_loss: 6.7111 - triplet_loss_accuracy: 0.0016 - activation_accuracy: 0.0047 - val_loss: 8.8502 - val_triplet_loss_loss: 0.2264 - val_activation_loss: 8.6238 - val_triplet_loss_accuracy: 0.0000e+00 - val_activation_accuracy: 0.0000e+00 - lr: 0.0100\n",
      "\n",
      "Epoch 00007: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 7/20\n",
      "40/40 [==============================] - ETA: 0s - loss: 7.0063 - triplet_loss_loss: 0.2709 - activation_loss: 6.7354 - triplet_loss_accuracy: 0.0016 - activation_accuracy: 0.0016WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "40/40 [==============================] - 8s 213ms/step - loss: 7.0063 - triplet_loss_loss: 0.2709 - activation_loss: 6.7354 - triplet_loss_accuracy: 0.0016 - activation_accuracy: 0.0016 - val_loss: 9.8609 - val_triplet_loss_loss: 0.2343 - val_activation_loss: 9.6265 - val_triplet_loss_accuracy: 0.0000e+00 - val_activation_accuracy: 0.0000e+00 - lr: 0.0100\n",
      "\n",
      "Epoch 00008: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 8/20\n",
      "40/40 [==============================] - ETA: 0s - loss: 7.0010 - triplet_loss_loss: 0.2659 - activation_loss: 6.7350 - triplet_loss_accuracy: 0.0000e+00 - activation_accuracy: 0.0031WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "40/40 [==============================] - 9s 222ms/step - loss: 7.0010 - triplet_loss_loss: 0.2659 - activation_loss: 6.7350 - triplet_loss_accuracy: 0.0000e+00 - activation_accuracy: 0.0031 - val_loss: 8.5755 - val_triplet_loss_loss: 0.2118 - val_activation_loss: 8.3637 - val_triplet_loss_accuracy: 0.0063 - val_activation_accuracy: 0.0000e+00 - lr: 0.0100\n",
      "\n",
      "Epoch 00009: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 9/20\n",
      "40/40 [==============================] - ETA: 0s - loss: 6.9785 - triplet_loss_loss: 0.2647 - activation_loss: 6.7137 - triplet_loss_accuracy: 0.0031 - activation_accuracy: 0.0031WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "40/40 [==============================] - 9s 217ms/step - loss: 6.9785 - triplet_loss_loss: 0.2647 - activation_loss: 6.7137 - triplet_loss_accuracy: 0.0031 - activation_accuracy: 0.0031 - val_loss: 9.0788 - val_triplet_loss_loss: 0.2155 - val_activation_loss: 8.8633 - val_triplet_loss_accuracy: 0.0000e+00 - val_activation_accuracy: 0.0000e+00 - lr: 0.0100\n",
      "\n",
      "Epoch 00010: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 10/20\n",
      "40/40 [==============================] - ETA: 0s - loss: 6.9471 - triplet_loss_loss: 0.2572 - activation_loss: 6.6898 - triplet_loss_accuracy: 0.0016 - activation_accuracy: 0.0031  WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "40/40 [==============================] - 9s 217ms/step - loss: 6.9471 - triplet_loss_loss: 0.2572 - activation_loss: 6.6898 - triplet_loss_accuracy: 0.0016 - activation_accuracy: 0.0031 - val_loss: 8.8113 - val_triplet_loss_loss: 0.2337 - val_activation_loss: 8.5777 - val_triplet_loss_accuracy: 0.0000e+00 - val_activation_accuracy: 0.0000e+00 - lr: 0.0100\n",
      "\n",
      "Epoch 00011: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 11/20\n",
      "40/40 [==============================] - ETA: 0s - loss: 6.9732 - triplet_loss_loss: 0.2556 - activation_loss: 6.7176 - triplet_loss_accuracy: 0.0016 - activation_accuracy: 0.0016WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "40/40 [==============================] - 9s 215ms/step - loss: 6.9732 - triplet_loss_loss: 0.2556 - activation_loss: 6.7176 - triplet_loss_accuracy: 0.0016 - activation_accuracy: 0.0016 - val_loss: 7.8523 - val_triplet_loss_loss: 0.2058 - val_activation_loss: 7.6465 - val_triplet_loss_accuracy: 0.0000e+00 - val_activation_accuracy: 0.0000e+00 - lr: 0.0100\n",
      "\n",
      "Epoch 00012: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 12/20\n",
      "40/40 [==============================] - ETA: 0s - loss: 6.8935 - triplet_loss_loss: 0.2444 - activation_loss: 6.6491 - triplet_loss_accuracy: 0.0016 - activation_accuracy: 0.0031WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 9s 232ms/step - loss: 6.8935 - triplet_loss_loss: 0.2444 - activation_loss: 6.6491 - triplet_loss_accuracy: 0.0016 - activation_accuracy: 0.0031 - val_loss: 8.1459 - val_triplet_loss_loss: 0.2092 - val_activation_loss: 7.9368 - val_triplet_loss_accuracy: 0.0000e+00 - val_activation_accuracy: 0.0000e+00 - lr: 0.0100\n",
      "\n",
      "Epoch 00013: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 13/20\n",
      "40/40 [==============================] - ETA: 0s - loss: 6.9203 - triplet_loss_loss: 0.2477 - activation_loss: 6.6726 - triplet_loss_accuracy: 0.0047 - activation_accuracy: 0.0063WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "40/40 [==============================] - 7s 184ms/step - loss: 6.9203 - triplet_loss_loss: 0.2477 - activation_loss: 6.6726 - triplet_loss_accuracy: 0.0047 - activation_accuracy: 0.0063 - val_loss: 7.5935 - val_triplet_loss_loss: 0.2173 - val_activation_loss: 7.3762 - val_triplet_loss_accuracy: 0.0000e+00 - val_activation_accuracy: 0.0125 - lr: 0.0100\n",
      "\n",
      "Epoch 00014: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 14/20\n",
      "40/40 [==============================] - ETA: 0s - loss: 6.9174 - triplet_loss_loss: 0.2425 - activation_loss: 6.6749 - triplet_loss_accuracy: 0.0000e+00 - activation_accuracy: 0.0016WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "40/40 [==============================] - 7s 182ms/step - loss: 6.9174 - triplet_loss_loss: 0.2425 - activation_loss: 6.6749 - triplet_loss_accuracy: 0.0000e+00 - activation_accuracy: 0.0016 - val_loss: 7.7811 - val_triplet_loss_loss: 0.2191 - val_activation_loss: 7.5619 - val_triplet_loss_accuracy: 0.0000e+00 - val_activation_accuracy: 0.0063 - lr: 0.0100\n",
      "\n",
      "Epoch 00015: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 15/20\n",
      "40/40 [==============================] - ETA: 0s - loss: 6.9053 - triplet_loss_loss: 0.2313 - activation_loss: 6.6740 - triplet_loss_accuracy: 0.0031 - activation_accuracy: 0.0016WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "40/40 [==============================] - 7s 185ms/step - loss: 6.9053 - triplet_loss_loss: 0.2313 - activation_loss: 6.6740 - triplet_loss_accuracy: 0.0031 - activation_accuracy: 0.0016 - val_loss: 7.4752 - val_triplet_loss_loss: 0.2086 - val_activation_loss: 7.2666 - val_triplet_loss_accuracy: 0.0063 - val_activation_accuracy: 0.0000e+00 - lr: 0.0100\n",
      "\n",
      "Epoch 00016: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 16/20\n",
      "40/40 [==============================] - ETA: 0s - loss: 6.9086 - triplet_loss_loss: 0.2329 - activation_loss: 6.6757 - triplet_loss_accuracy: 0.0031 - activation_accuracy: 0.0016WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "40/40 [==============================] - 7s 184ms/step - loss: 6.9086 - triplet_loss_loss: 0.2329 - activation_loss: 6.6757 - triplet_loss_accuracy: 0.0031 - activation_accuracy: 0.0016 - val_loss: 7.5770 - val_triplet_loss_loss: 0.2065 - val_activation_loss: 7.3705 - val_triplet_loss_accuracy: 0.0000e+00 - val_activation_accuracy: 0.0000e+00 - lr: 0.0100\n",
      "\n",
      "Epoch 00017: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 17/20\n",
      "40/40 [==============================] - ETA: 0s - loss: 6.8620 - triplet_loss_loss: 0.2244 - activation_loss: 6.6377 - triplet_loss_accuracy: 0.0000e+00 - activation_accuracy: 0.0031 WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "40/40 [==============================] - 8s 192ms/step - loss: 6.8620 - triplet_loss_loss: 0.2244 - activation_loss: 6.6377 - triplet_loss_accuracy: 0.0000e+00 - activation_accuracy: 0.0031 - val_loss: 7.7182 - val_triplet_loss_loss: 0.2103 - val_activation_loss: 7.5079 - val_triplet_loss_accuracy: 0.0000e+00 - val_activation_accuracy: 0.0000e+00 - lr: 0.0100\n",
      "\n",
      "Epoch 00018: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 18/20\n",
      "40/40 [==============================] - ETA: 0s - loss: 6.8406 - triplet_loss_loss: 0.2057 - activation_loss: 6.6348 - triplet_loss_accuracy: 0.0016 - activation_accuracy: 0.0031WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "40/40 [==============================] - 9s 211ms/step - loss: 6.8406 - triplet_loss_loss: 0.2057 - activation_loss: 6.6348 - triplet_loss_accuracy: 0.0016 - activation_accuracy: 0.0031 - val_loss: 7.7498 - val_triplet_loss_loss: 0.2191 - val_activation_loss: 7.5307 - val_triplet_loss_accuracy: 0.0063 - val_activation_accuracy: 0.0000e+00 - lr: 0.0100\n",
      "\n",
      "Epoch 00019: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 19/20\n",
      "40/40 [==============================] - ETA: 0s - loss: 6.8273 - triplet_loss_loss: 0.2140 - activation_loss: 6.6133 - triplet_loss_accuracy: 0.0063 - activation_accuracy: 0.0016WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "40/40 [==============================] - 8s 200ms/step - loss: 6.8273 - triplet_loss_loss: 0.2140 - activation_loss: 6.6133 - triplet_loss_accuracy: 0.0063 - activation_accuracy: 0.0016 - val_loss: 7.2527 - val_triplet_loss_loss: 0.2087 - val_activation_loss: 7.0440 - val_triplet_loss_accuracy: 0.0000e+00 - val_activation_accuracy: 0.0000e+00 - lr: 0.0100\n",
      "\n",
      "Epoch 00020: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 20/20\n",
      "40/40 [==============================] - ETA: 0s - loss: 6.8080 - triplet_loss_loss: 0.2122 - activation_loss: 6.5959 - triplet_loss_accuracy: 0.0000e+00 - activation_accuracy: 0.0016WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "40/40 [==============================] - 8s 210ms/step - loss: 6.8080 - triplet_loss_loss: 0.2122 - activation_loss: 6.5959 - triplet_loss_accuracy: 0.0000e+00 - activation_accuracy: 0.0016 - val_loss: 7.3353 - val_triplet_loss_loss: 0.2058 - val_activation_loss: 7.1296 - val_triplet_loss_accuracy: 0.0000e+00 - val_activation_accuracy: 0.0063 - lr: 0.0100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbbe6851610>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Loading, if large size, use batch\n",
    "# from utils import generator_batch_triplet\n",
    "\n",
    "train_generator = generator_batch_triplet(img_path_list = train_img_path, \n",
    "                                  img_label_list = train_person_ids,\n",
    "                                 nbr_classes = nbr_person_ids,\n",
    "                                 img_width=img_width, img_height= img_height,\n",
    "                                 P = 16, K=4, shuffle=True,\n",
    "                                 save_to_dir = False, augment = True)\n",
    "\n",
    "val_generator = generator_batch_triplet(img_path_list = val_img_path,\n",
    "                               img_label_list = val_person_ids, nbr_classes=nbr_person_ids,\n",
    "                               img_width=img_width, img_height= img_height,\n",
    "                               P=16, K=4, shuffle = False,\n",
    "                               save_to_dir = False, augment= False)\n",
    "\n",
    "\n",
    "# from tensorflow.keras.callbacks import Checkpoint\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "# CALLBACK\n",
    "checkpoint = ModelCheckpoint('./cnn_baseline.h5', monitor='val_accuracy',\n",
    "                            verbose=1, save_best_only=True)\n",
    "learning_rate_decay = LearningRateScheduler(lr_decay_basic, verbose=1)\n",
    "\n",
    "triplet_model.fit(train_generator, \n",
    "                   steps_per_epoch=len(train_img_path) // batch_size,\n",
    "                   validation_data = val_generator,\n",
    "                  validation_steps = len(val_img_path) // batch_size,\n",
    "                  batch_size=batch_size,verbose=1,shuffle=True,\n",
    "                  epochs=nbr_epochs,callbacks=[checkpoint, learning_rate_decay])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3464f9d0",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "92eeff28",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width = 64\n",
    "img_height = 128\n",
    "USE_Label_Smoothing = True\n",
    "batch_size = 128\n",
    "model_path = './cnn_baseline.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6597ab1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "query_folder = '/Users/DanDan/Desktop/七月在线/机器学习原理/第六阶段CV推荐NLP实战/CV/Market-1501-v15.09.15/query'\n",
    "# 3368 images in the query set\n",
    "query_root = os.path.join(os.getcwd(), query_folder)\n",
    "\n",
    "query_image_names = sorted([x for x in os.listdir(query_root) if x.endswith('.jpg')])\n",
    "\n",
    "query_img_name, query_img_path = zip(*[(img_file_png[:-4], os.path.join(query_root))\n",
    "                                     for img_file_png in query_image_names])\n",
    "\n",
    "\n",
    "\n",
    "gallery_folder = '/Users/DanDan/Desktop/七月在线/机器学习原理/第六阶段CV推荐NLP实战/CV/Market-1501-v15.09.15/gt_bbox'\n",
    "# 25259 images in the gallery folder\n",
    "\n",
    "gallery_root = os.path.join(os.getcwd(),gallery_folder)\n",
    "gallery_image_names = sorted([x for x in os.listdir(gallery_root) if x.endswith('.jpg')])\n",
    "\n",
    "# remove the duplicated images from the gallery set\n",
    "gallery_image_names = [x for x in gallery_image_names if x not in query_image_names]\n",
    "gallery_img_name, gallery_img_path = zip(*[(img_file_png[:-4], os.path.join(gallery_root)) \n",
    "                                      for img_file_png in gallery_image_names])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "69182fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_10 (InputLayer)          [(None, 64, 64, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " Conv1 (Conv2D)                 (None, 32, 32, 16)   432         ['input_10[0][0]']               \n",
      "                                                                                                  \n",
      " bn_Conv1 (BatchNormalization)  (None, 32, 32, 16)   64          ['Conv1[0][0]']                  \n",
      "                                                                                                  \n",
      " Conv1_relu (ReLU)              (None, 32, 32, 16)   0           ['bn_Conv1[0][0]']               \n",
      "                                                                                                  \n",
      " expanded_conv_depthwise (Depth  (None, 32, 32, 16)  144         ['Conv1_relu[0][0]']             \n",
      " wiseConv2D)                                                                                      \n",
      "                                                                                                  \n",
      " expanded_conv_depthwise_BN (Ba  (None, 32, 32, 16)  64          ['expanded_conv_depthwise[0][0]']\n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " expanded_conv_depthwise_relu (  (None, 32, 32, 16)  0           ['expanded_conv_depthwise_BN[0][0\n",
      " ReLU)                                                           ]']                              \n",
      "                                                                                                  \n",
      " expanded_conv_project (Conv2D)  (None, 32, 32, 8)   128         ['expanded_conv_depthwise_relu[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " expanded_conv_project_BN (Batc  (None, 32, 32, 8)   32          ['expanded_conv_project[0][0]']  \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " block_1_expand (Conv2D)        (None, 32, 32, 48)   384         ['expanded_conv_project_BN[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " block_1_expand_BN (BatchNormal  (None, 32, 32, 48)  192         ['block_1_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_1_expand_relu (ReLU)     (None, 32, 32, 48)   0           ['block_1_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_1_pad (ZeroPadding2D)    (None, 33, 33, 48)   0           ['block_1_expand_relu[0][0]']    \n",
      "                                                                                                  \n",
      " block_1_depthwise (DepthwiseCo  (None, 16, 16, 48)  432         ['block_1_pad[0][0]']            \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_1_depthwise_BN (BatchNor  (None, 16, 16, 48)  192         ['block_1_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_1_depthwise_relu (ReLU)  (None, 16, 16, 48)   0           ['block_1_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_1_project (Conv2D)       (None, 16, 16, 16)   768         ['block_1_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_1_project_BN (BatchNorma  (None, 16, 16, 16)  64          ['block_1_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_2_expand (Conv2D)        (None, 16, 16, 96)   1536        ['block_1_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_2_expand_BN (BatchNormal  (None, 16, 16, 96)  384         ['block_2_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_2_expand_relu (ReLU)     (None, 16, 16, 96)   0           ['block_2_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_2_depthwise (DepthwiseCo  (None, 16, 16, 96)  864         ['block_2_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_2_depthwise_BN (BatchNor  (None, 16, 16, 96)  384         ['block_2_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_2_depthwise_relu (ReLU)  (None, 16, 16, 96)   0           ['block_2_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_2_project (Conv2D)       (None, 16, 16, 16)   1536        ['block_2_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_2_project_BN (BatchNorma  (None, 16, 16, 16)  64          ['block_2_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_2_add (Add)              (None, 16, 16, 16)   0           ['block_1_project_BN[0][0]',     \n",
      "                                                                  'block_2_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_3_expand (Conv2D)        (None, 16, 16, 96)   1536        ['block_2_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_3_expand_BN (BatchNormal  (None, 16, 16, 96)  384         ['block_3_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_3_expand_relu (ReLU)     (None, 16, 16, 96)   0           ['block_3_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_3_pad (ZeroPadding2D)    (None, 17, 17, 96)   0           ['block_3_expand_relu[0][0]']    \n",
      "                                                                                                  \n",
      " block_3_depthwise (DepthwiseCo  (None, 8, 8, 96)    864         ['block_3_pad[0][0]']            \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_3_depthwise_BN (BatchNor  (None, 8, 8, 96)    384         ['block_3_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_3_depthwise_relu (ReLU)  (None, 8, 8, 96)     0           ['block_3_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_3_project (Conv2D)       (None, 8, 8, 16)     1536        ['block_3_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_3_project_BN (BatchNorma  (None, 8, 8, 16)    64          ['block_3_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_4_expand (Conv2D)        (None, 8, 8, 96)     1536        ['block_3_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_4_expand_BN (BatchNormal  (None, 8, 8, 96)    384         ['block_4_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_4_expand_relu (ReLU)     (None, 8, 8, 96)     0           ['block_4_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_4_depthwise (DepthwiseCo  (None, 8, 8, 96)    864         ['block_4_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_4_depthwise_BN (BatchNor  (None, 8, 8, 96)    384         ['block_4_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_4_depthwise_relu (ReLU)  (None, 8, 8, 96)     0           ['block_4_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_4_project (Conv2D)       (None, 8, 8, 16)     1536        ['block_4_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_4_project_BN (BatchNorma  (None, 8, 8, 16)    64          ['block_4_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_4_add (Add)              (None, 8, 8, 16)     0           ['block_3_project_BN[0][0]',     \n",
      "                                                                  'block_4_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_5_expand (Conv2D)        (None, 8, 8, 96)     1536        ['block_4_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_5_expand_BN (BatchNormal  (None, 8, 8, 96)    384         ['block_5_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_5_expand_relu (ReLU)     (None, 8, 8, 96)     0           ['block_5_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_5_depthwise (DepthwiseCo  (None, 8, 8, 96)    864         ['block_5_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_5_depthwise_BN (BatchNor  (None, 8, 8, 96)    384         ['block_5_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_5_depthwise_relu (ReLU)  (None, 8, 8, 96)     0           ['block_5_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_5_project (Conv2D)       (None, 8, 8, 16)     1536        ['block_5_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_5_project_BN (BatchNorma  (None, 8, 8, 16)    64          ['block_5_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_5_add (Add)              (None, 8, 8, 16)     0           ['block_4_add[0][0]',            \n",
      "                                                                  'block_5_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_6_expand (Conv2D)        (None, 8, 8, 96)     1536        ['block_5_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_6_expand_BN (BatchNormal  (None, 8, 8, 96)    384         ['block_6_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_6_expand_relu (ReLU)     (None, 8, 8, 96)     0           ['block_6_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_6_pad (ZeroPadding2D)    (None, 9, 9, 96)     0           ['block_6_expand_relu[0][0]']    \n",
      "                                                                                                  \n",
      " block_6_depthwise (DepthwiseCo  (None, 4, 4, 96)    864         ['block_6_pad[0][0]']            \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_6_depthwise_BN (BatchNor  (None, 4, 4, 96)    384         ['block_6_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_6_depthwise_relu (ReLU)  (None, 4, 4, 96)     0           ['block_6_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_6_project (Conv2D)       (None, 4, 4, 32)     3072        ['block_6_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_6_project_BN (BatchNorma  (None, 4, 4, 32)    128         ['block_6_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_7_expand (Conv2D)        (None, 4, 4, 192)    6144        ['block_6_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_7_expand_BN (BatchNormal  (None, 4, 4, 192)   768         ['block_7_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_7_expand_relu (ReLU)     (None, 4, 4, 192)    0           ['block_7_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_7_depthwise (DepthwiseCo  (None, 4, 4, 192)   1728        ['block_7_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_7_depthwise_BN (BatchNor  (None, 4, 4, 192)   768         ['block_7_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_7_depthwise_relu (ReLU)  (None, 4, 4, 192)    0           ['block_7_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_7_project (Conv2D)       (None, 4, 4, 32)     6144        ['block_7_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_7_project_BN (BatchNorma  (None, 4, 4, 32)    128         ['block_7_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_7_add (Add)              (None, 4, 4, 32)     0           ['block_6_project_BN[0][0]',     \n",
      "                                                                  'block_7_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_8_expand (Conv2D)        (None, 4, 4, 192)    6144        ['block_7_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_8_expand_BN (BatchNormal  (None, 4, 4, 192)   768         ['block_8_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_8_expand_relu (ReLU)     (None, 4, 4, 192)    0           ['block_8_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_8_depthwise (DepthwiseCo  (None, 4, 4, 192)   1728        ['block_8_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_8_depthwise_BN (BatchNor  (None, 4, 4, 192)   768         ['block_8_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_8_depthwise_relu (ReLU)  (None, 4, 4, 192)    0           ['block_8_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_8_project (Conv2D)       (None, 4, 4, 32)     6144        ['block_8_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_8_project_BN (BatchNorma  (None, 4, 4, 32)    128         ['block_8_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_8_add (Add)              (None, 4, 4, 32)     0           ['block_7_add[0][0]',            \n",
      "                                                                  'block_8_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_9_expand (Conv2D)        (None, 4, 4, 192)    6144        ['block_8_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_9_expand_BN (BatchNormal  (None, 4, 4, 192)   768         ['block_9_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_9_expand_relu (ReLU)     (None, 4, 4, 192)    0           ['block_9_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_9_depthwise (DepthwiseCo  (None, 4, 4, 192)   1728        ['block_9_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_9_depthwise_BN (BatchNor  (None, 4, 4, 192)   768         ['block_9_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_9_depthwise_relu (ReLU)  (None, 4, 4, 192)    0           ['block_9_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_9_project (Conv2D)       (None, 4, 4, 32)     6144        ['block_9_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_9_project_BN (BatchNorma  (None, 4, 4, 32)    128         ['block_9_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_9_add (Add)              (None, 4, 4, 32)     0           ['block_8_add[0][0]',            \n",
      "                                                                  'block_9_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_10_expand (Conv2D)       (None, 4, 4, 192)    6144        ['block_9_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_10_expand_BN (BatchNorma  (None, 4, 4, 192)   768         ['block_10_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_10_expand_relu (ReLU)    (None, 4, 4, 192)    0           ['block_10_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_10_depthwise (DepthwiseC  (None, 4, 4, 192)   1728        ['block_10_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_10_depthwise_BN (BatchNo  (None, 4, 4, 192)   768         ['block_10_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_10_depthwise_relu (ReLU)  (None, 4, 4, 192)   0           ['block_10_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_10_project (Conv2D)      (None, 4, 4, 48)     9216        ['block_10_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_10_project_BN (BatchNorm  (None, 4, 4, 48)    192         ['block_10_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_11_expand (Conv2D)       (None, 4, 4, 288)    13824       ['block_10_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_11_expand_BN (BatchNorma  (None, 4, 4, 288)   1152        ['block_11_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_11_expand_relu (ReLU)    (None, 4, 4, 288)    0           ['block_11_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_11_depthwise (DepthwiseC  (None, 4, 4, 288)   2592        ['block_11_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_11_depthwise_BN (BatchNo  (None, 4, 4, 288)   1152        ['block_11_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_11_depthwise_relu (ReLU)  (None, 4, 4, 288)   0           ['block_11_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_11_project (Conv2D)      (None, 4, 4, 48)     13824       ['block_11_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_11_project_BN (BatchNorm  (None, 4, 4, 48)    192         ['block_11_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_11_add (Add)             (None, 4, 4, 48)     0           ['block_10_project_BN[0][0]',    \n",
      "                                                                  'block_11_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_12_expand (Conv2D)       (None, 4, 4, 288)    13824       ['block_11_add[0][0]']           \n",
      "                                                                                                  \n",
      " block_12_expand_BN (BatchNorma  (None, 4, 4, 288)   1152        ['block_12_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_12_expand_relu (ReLU)    (None, 4, 4, 288)    0           ['block_12_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_12_depthwise (DepthwiseC  (None, 4, 4, 288)   2592        ['block_12_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_12_depthwise_BN (BatchNo  (None, 4, 4, 288)   1152        ['block_12_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_12_depthwise_relu (ReLU)  (None, 4, 4, 288)   0           ['block_12_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_12_project (Conv2D)      (None, 4, 4, 48)     13824       ['block_12_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_12_project_BN (BatchNorm  (None, 4, 4, 48)    192         ['block_12_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_12_add (Add)             (None, 4, 4, 48)     0           ['block_11_add[0][0]',           \n",
      "                                                                  'block_12_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_13_expand (Conv2D)       (None, 4, 4, 288)    13824       ['block_12_add[0][0]']           \n",
      "                                                                                                  \n",
      " block_13_expand_BN (BatchNorma  (None, 4, 4, 288)   1152        ['block_13_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_13_expand_relu (ReLU)    (None, 4, 4, 288)    0           ['block_13_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_13_pad (ZeroPadding2D)   (None, 5, 5, 288)    0           ['block_13_expand_relu[0][0]']   \n",
      "                                                                                                  \n",
      " block_13_depthwise (DepthwiseC  (None, 2, 2, 288)   2592        ['block_13_pad[0][0]']           \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_13_depthwise_BN (BatchNo  (None, 2, 2, 288)   1152        ['block_13_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_13_depthwise_relu (ReLU)  (None, 2, 2, 288)   0           ['block_13_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_13_project (Conv2D)      (None, 2, 2, 80)     23040       ['block_13_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_13_project_BN (BatchNorm  (None, 2, 2, 80)    320         ['block_13_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_14_expand (Conv2D)       (None, 2, 2, 480)    38400       ['block_13_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_14_expand_BN (BatchNorma  (None, 2, 2, 480)   1920        ['block_14_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_14_expand_relu (ReLU)    (None, 2, 2, 480)    0           ['block_14_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_14_depthwise (DepthwiseC  (None, 2, 2, 480)   4320        ['block_14_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_14_depthwise_BN (BatchNo  (None, 2, 2, 480)   1920        ['block_14_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_14_depthwise_relu (ReLU)  (None, 2, 2, 480)   0           ['block_14_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_14_project (Conv2D)      (None, 2, 2, 80)     38400       ['block_14_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_14_project_BN (BatchNorm  (None, 2, 2, 80)    320         ['block_14_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_14_add (Add)             (None, 2, 2, 80)     0           ['block_13_project_BN[0][0]',    \n",
      "                                                                  'block_14_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_15_expand (Conv2D)       (None, 2, 2, 480)    38400       ['block_14_add[0][0]']           \n",
      "                                                                                                  \n",
      " block_15_expand_BN (BatchNorma  (None, 2, 2, 480)   1920        ['block_15_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_15_expand_relu (ReLU)    (None, 2, 2, 480)    0           ['block_15_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_15_depthwise (DepthwiseC  (None, 2, 2, 480)   4320        ['block_15_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_15_depthwise_BN (BatchNo  (None, 2, 2, 480)   1920        ['block_15_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_15_depthwise_relu (ReLU)  (None, 2, 2, 480)   0           ['block_15_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_15_project (Conv2D)      (None, 2, 2, 80)     38400       ['block_15_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_15_project_BN (BatchNorm  (None, 2, 2, 80)    320         ['block_15_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_15_add (Add)             (None, 2, 2, 80)     0           ['block_14_add[0][0]',           \n",
      "                                                                  'block_15_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_16_expand (Conv2D)       (None, 2, 2, 480)    38400       ['block_15_add[0][0]']           \n",
      "                                                                                                  \n",
      " block_16_expand_BN (BatchNorma  (None, 2, 2, 480)   1920        ['block_16_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_16_expand_relu (ReLU)    (None, 2, 2, 480)    0           ['block_16_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_16_depthwise (DepthwiseC  (None, 2, 2, 480)   4320        ['block_16_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_16_depthwise_BN (BatchNo  (None, 2, 2, 480)   1920        ['block_16_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_16_depthwise_relu (ReLU)  (None, 2, 2, 480)   0           ['block_16_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_16_project (Conv2D)      (None, 2, 2, 160)    76800       ['block_16_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_16_project_BN (BatchNorm  (None, 2, 2, 160)   640         ['block_16_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " Conv_1 (Conv2D)                (None, 2, 2, 1280)   204800      ['block_16_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " Conv_1_bn (BatchNormalization)  (None, 2, 2, 1280)  5120        ['Conv_1[0][0]']                 \n",
      "                                                                                                  \n",
      " out_relu (ReLU)                (None, 2, 2, 1280)   0           ['Conv_1_bn[0][0]']              \n",
      "                                                                                                  \n",
      " global_max_pooling2d_9 (Global  (None, 1280)        0           ['out_relu[0][0]']               \n",
      " MaxPooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 751)          962031      ['global_max_pooling2d_9[0][0]'] \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 751)          0           ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,668,255\n",
      "Trainable params: 1,649,711\n",
      "Non-trainable params: 18,544\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "if USE_Label_Smoothing:\n",
    "    \n",
    "#     from utils import cross_entropy_label_smoothing\n",
    "    model = load_model(model_path, \n",
    "                      custom_objects={'cross_entropy_label_smoothing': cross_entropy_label_smoothing})\n",
    "else:\n",
    "    model = load_model(model_path)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "72e9ead9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_features = model.get_layer('global_max_pooling2d_9').output\n",
    "# 1280-D\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "model_extract_features = Model(model.input, dense_features)\n",
    "\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "optimizer = SGD(learning_rate = 0.01)\n",
    "\n",
    "model_extract_features.compile(loss = 'categorical_crossentropy',\n",
    "                              optimizer = optimizer,\n",
    "                              metrics =['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ffffbc10",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'generator_batch_predict' from 'tensorflow.keras.utils' (/opt/anaconda3/lib/python3.8/site-packages/keras/api/_v2/keras/utils/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_2996/3769880708.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgenerator_batch_predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'generator_batch_predict' from 'tensorflow.keras.utils' (/opt/anaconda3/lib/python3.8/site-packages/keras/api/_v2/keras/utils/__init__.py)"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import generator_batch_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "146cf294",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'generator_batch_predict' from 'tensorflow.keras.utils' (/opt/anaconda3/lib/python3.8/site-packages/keras/api/_v2/keras/utils/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_2996/3002791345.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgenerator_batch_predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m query_generator = generator_batch_predict(\n\u001b[1;32m      3\u001b[0m     \u001b[0mimg_path_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery_img_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_width\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_width\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                          \u001b[0mimg_height\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_height\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                          batch_size = batch_size)\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'generator_batch_predict' from 'tensorflow.keras.utils' (/opt/anaconda3/lib/python3.8/site-packages/keras/api/_v2/keras/utils/__init__.py)"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import generator_batch_predict\n",
    "query_generator = generator_batch_predict(\n",
    "    img_path_list = query_img_path, img_width = img_width,\n",
    "                                         img_height = img_height,\n",
    "                                         batch_size = batch_size)\n",
    "\n",
    "query_features = model_extract_features.predict(query_generator, verbose=1,\n",
    "      steps=len(query_img_path) / batch_size + 1)\n",
    "\n",
    "from sklearn.preprocessing import normalize\n",
    "query_features = normalize(query_features, norm = 'l2')\n",
    "# shape: (3368, 1280)\n",
    "print('query features shape:', query_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c28b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gallery_generator = generator_batch_predict(img_path_list = gallery_img_path,\n",
    "                                           img_width = img_width,\n",
    "                                           img_height=img_height,\n",
    "                                           batch_size=batch_size)\n",
    "\n",
    "gallery_features = model_extract_features.predict(gallery_generator, verbose=1,\n",
    "                                    steps=len(gallery_img_path) / batch_size + 1)\n",
    "\n",
    "gallery_features = normalize(gallery_features, norm ='l2')\n",
    "print('gallery features shape:', gallery_features.shape)\n",
    "# shape : (25259, 1280)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be612f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a -- vector, b --vector, similarity ? Sim(a, b) = dot_product(a, b)\n",
    "# a -- vector, B -- matrix, similarity ? \n",
    "# A -- matrix, B -- matrix, \n",
    "\n",
    "import numpy as np\n",
    "similarity_matrix = np.dot(query_features, np.transpose(gallery_features))\n",
    "# 3368 X 1280, (25259 X 1280).T\n",
    "\n",
    "distance_matrix = 1 - similarity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84ffbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_list = np.argsort(similarity_matrix, axis=1)\n",
    "# each row in idx_list is a prediction\n",
    "# idx_list[row][0] is the index of the prediciton ID\n",
    "\n",
    "top_1_acc = 0\n",
    "for i, query_name in enumerate(query_img_name):\n",
    "    query_id = int(query_name[:4])\n",
    "    \n",
    "    pred = model_extract_features.predict(idx_list, verbose=1,\n",
    "      steps=len(query_img_path) / batch_size + 1)\n",
    "    \n",
    "    top_1_acc += pred\n",
    "    \n",
    "top_1_acc / len(query_img_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13faacd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tensorflow.__version__)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
